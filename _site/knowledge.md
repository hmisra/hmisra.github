
---
layout: page
type: sidebar
title: Knowledge
---

    
                ### Machine Learning

                #### Concepts

                <a href = "/"></a> &nbsp; &nbsp;
                    
                <a href = "/">structured mean field</a> &nbsp; &nbsp;
                    
                <a href = "/">fitting logistic regression with iterative reweighted least squares</a> &nbsp; &nbsp;
                    
                <a href = "/">variational Bayes</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian networks</a> &nbsp; &nbsp;
                    
                <a href = "/">perceptron algorithm</a> &nbsp; &nbsp;
                    
                <a href = "/">latent semantic analysis</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian parameter estimation: multinomial distribution</a> &nbsp; &nbsp;
                    
                <a href = "/">linear regression: closed-form solution</a> &nbsp; &nbsp;
                    
                <a href = "/">learning linear dynamical systems</a> &nbsp; &nbsp;
                    
                <a href = "/">MRF parameter learning</a> &nbsp; &nbsp;
                    
                <a href = "/">soft margin SVM</a> &nbsp; &nbsp;
                    
                <a href = "/">Indian buffet process</a> &nbsp; &nbsp;
                    
                <a href = "/">annealed importance sampling</a> &nbsp; &nbsp;
                    
                <a href = "/">Akaike information criterion</a> &nbsp; &nbsp;
                    
                <a href = "/">feed-forward neural nets</a> &nbsp; &nbsp;
                    
                <a href = "/">k-means++</a> &nbsp; &nbsp;
                    
                <a href = "/">Markov chain Monte Carlo</a> &nbsp; &nbsp;
                    
                <a href = "/">Markov models</a> &nbsp; &nbsp;
                    
                <a href = "/">slice sampling</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian decision theory</a> &nbsp; &nbsp;
                    
                <a href = "/">linear-Gaussian models</a> &nbsp; &nbsp;
                    
                <a href = "/">maximum likelihood in exponential families</a> &nbsp; &nbsp;
                    
                <a href = "/">learning Bayes net parameters with missing data</a> &nbsp; &nbsp;
                    
                <a href = "/">support vector machine</a> &nbsp; &nbsp;
                    
                <a href = "/">hierarchical Dirichlet process</a> &nbsp; &nbsp;
                    
                <a href = "/">linear regression as maximum likelihood</a> &nbsp; &nbsp;
                    
                <a href = "/">AdaBoost</a> &nbsp; &nbsp;
                    
                <a href = "/">logistic regression</a> &nbsp; &nbsp;
                    
                <a href = "/">sparse coding</a> &nbsp; &nbsp;
                    
                <a href = "/">LASSO</a> &nbsp; &nbsp;
                    
                <a href = "/">MCMC convergence</a> &nbsp; &nbsp;
                    
                <a href = "/">binary linear classifiers</a> &nbsp; &nbsp;
                    
                <a href = "/">information form for multivariate Gaussians</a> &nbsp; &nbsp;
                    
                <a href = "/">hidden Markov models</a> &nbsp; &nbsp;
                    
                <a href = "/">Fisher's linear discriminant</a> &nbsp; &nbsp;
                    
                <a href = "/">bagging</a> &nbsp; &nbsp;
                    
                <a href = "/">support vector regression</a> &nbsp; &nbsp;
                    
                <a href = "/">latent Dirichlet allocation</a> &nbsp; &nbsp;
                    
                <a href = "/">variational inference</a> &nbsp; &nbsp;
                    
                <a href = "/">mean field approximation</a> &nbsp; &nbsp;
                    
                <a href = "/">constructing kernels</a> &nbsp; &nbsp;
                    
                <a href = "/">naive Bayes</a> &nbsp; &nbsp;
                    
                <a href = "/">sequential Monte Carlo</a> &nbsp; &nbsp;
                    
                <a href = "/">variational linear regression</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian model averaging</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayes net structure learning</a> &nbsp; &nbsp;
                    
                <a href = "/">conditional random fields</a> &nbsp; &nbsp;
                    
                <a href = "/">tangent propagation</a> &nbsp; &nbsp;
                    
                <a href = "/">factor analysis</a> &nbsp; &nbsp;
                    
                <a href = "/">F measure</a> &nbsp; &nbsp;
                    
                <a href = "/">VC dimension</a> &nbsp; &nbsp;
                    
                <a href = "/">K nearest neighbors</a> &nbsp; &nbsp;
                    
                <a href = "/">random forests</a> &nbsp; &nbsp;
                    
                <a href = "/">ridge regression</a> &nbsp; &nbsp;
                    
                <a href = "/">Expectation-Maximization algorithm</a> &nbsp; &nbsp;
                    
                <a href = "/">principal component analysis (proof)</a> &nbsp; &nbsp;
                    
                <a href = "/">Boltzmann machines</a> &nbsp; &nbsp;
                    
                <a href = "/">Metropolis-Hastings algorithm</a> &nbsp; &nbsp;
                    
                <a href = "/">variational logistic regression</a> &nbsp; &nbsp;
                    
                <a href = "/">bias-variance decomposition</a> &nbsp; &nbsp;
                    
                <a href = "/">forward-backward algorithm</a> &nbsp; &nbsp;
                    
                <a href = "/">CRP clustering</a> &nbsp; &nbsp;
                    
                <a href = "/">Markov random fields</a> &nbsp; &nbsp;
                    
                <a href = "/">Gibbs sampling</a> &nbsp; &nbsp;
                    
                <a href = "/">collapsed Gibbs sampling</a> &nbsp; &nbsp;
                    
                <a href = "/">gamma distribution</a> &nbsp; &nbsp;
                    
                <a href = "/">learning invariances in neural nets</a> &nbsp; &nbsp;
                    
                <a href = "/">Chow-Liu trees</a> &nbsp; &nbsp;
                    
                <a href = "/">soft weight sharing in neural nets</a> &nbsp; &nbsp;
                    
                <a href = "/">Back propagation for second-order methods</a> &nbsp; &nbsp;
                    
                <a href = "/">mixture of Gaussians models</a> &nbsp; &nbsp;
                    
                <a href = "/">restricted Boltzmann machines</a> &nbsp; &nbsp;
                    
                <a href = "/">Gaussian discriminant analysis</a> &nbsp; &nbsp;
                    
                <a href = "/">basis function expansions</a> &nbsp; &nbsp;
                    
                <a href = "/">beta process</a> &nbsp; &nbsp;
                    
                <a href = "/">maximum likelihood</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian model comparison</a> &nbsp; &nbsp;
                    
                <a href = "/">Gaussian process regression</a> &nbsp; &nbsp;
                    
                <a href = "/">Chinese restaurant franchise</a> &nbsp; &nbsp;
                    
                <a href = "/">Gibbs sampling as a special case of Metropolis-Hastings</a> &nbsp; &nbsp;
                    
                <a href = "/">SVM vs. logistic regression</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian linear regression</a> &nbsp; &nbsp;
                    
                <a href = "/">MAP parameter estimation</a> &nbsp; &nbsp;
                    
                <a href = "/">Viterbi algorithm</a> &nbsp; &nbsp;
                    
                <a href = "/">Chinese restaurant process</a> &nbsp; &nbsp;
                    
                <a href = "/">generalization</a> &nbsp; &nbsp;
                    
                <a href = "/">learning GP hyperparameters</a> &nbsp; &nbsp;
                    
                <a href = "/">multidimensional scaling</a> &nbsp; &nbsp;
                    
                <a href = "/">weight decay in neural networks</a> &nbsp; &nbsp;
                    
                <a href = "/">decision trees</a> &nbsp; &nbsp;
                    
                <a href = "/">variational inference and exponential families</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian logistic regression</a> &nbsp; &nbsp;
                    
                <a href = "/">GP classification with the Laplace approximation</a> &nbsp; &nbsp;
                    
                <a href = "/">EM algorithm for PCA</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian parameter estimation</a> &nbsp; &nbsp;
                    
                <a href = "/">comparing Gaussian mixtures and k-means</a> &nbsp; &nbsp;
                    
                <a href = "/">cross validation</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian naive Bayes</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian PCA</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian parameter estimation: Gaussian distribution</a> &nbsp; &nbsp;
                    
                <a href = "/">Gaussian process classification</a> &nbsp; &nbsp;
                    
                <a href = "/">principal component analysis</a> &nbsp; &nbsp;
                    
                <a href = "/">unsupervised pre-training</a> &nbsp; &nbsp;
                    
                <a href = "/">independent component analysis</a> &nbsp; &nbsp;
                    
                <a href = "/">early stopping</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayes net parameter learning</a> &nbsp; &nbsp;
                    
                <a href = "/">Laplace approximation</a> &nbsp; &nbsp;
                    
                <a href = "/">variational mixture of Gaussians</a> &nbsp; &nbsp;
                    
                <a href = "/">SVM optimality conditions</a> &nbsp; &nbsp;
                    
                <a href = "/">recurrent neural networks</a> &nbsp; &nbsp;
                    
                <a href = "/">Jensen's inequality</a> &nbsp; &nbsp;
                    
                <a href = "/">probit regression</a> &nbsp; &nbsp;
                    
                <a href = "/">Gaussian processes</a> &nbsp; &nbsp;
                    
                <a href = "/">probabilistic PCA</a> &nbsp; &nbsp;
                    
                <a href = "/">Hopfield networks</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian parameter estimation in exponential families</a> &nbsp; &nbsp;
                    
                <a href = "/">kernel trick</a> &nbsp; &nbsp;
                    
                <a href = "/">boosting as optimization</a> &nbsp; &nbsp;
                    
                <a href = "/">probabilistic Latent Semantic Analysis</a> &nbsp; &nbsp;
                    
                <a href = "/">multinomial logistic regression</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayes rule</a> &nbsp; &nbsp;
                    
                <a href = "/">Hamiltonian Monte Carlo</a> &nbsp; &nbsp;
                    
                <a href = "/">Markov chains</a> &nbsp; &nbsp;
                    
                <a href = "/">Bayesian parameter estimation: multivariate Gaussians</a> &nbsp; &nbsp;
                    
                <a href = "/">curse of dimensionality</a> &nbsp; &nbsp;
                    
                <a href = "/">ridge regression as SVD</a> &nbsp; &nbsp;
                    
                <a href = "/">kernel SVM</a> &nbsp; &nbsp;
                    
                <a href = "/">k-means</a> &nbsp; &nbsp;
                    
                <a href = "/">precision and recall</a> &nbsp; &nbsp;
                    
                <a href = "/">deep belief networks</a> &nbsp; &nbsp;
                    
                <a href = "/">linear regression</a> &nbsp; &nbsp;
                    
                <a href = "/">generalized linear models</a> &nbsp; &nbsp;
                    
                <a href = "/">IBP linear-Gaussian model</a> &nbsp; &nbsp;
                    
                <a href = "/">computations on multivariate Gaussians</a> &nbsp; &nbsp;
                    
                <a href = "/">Baum-Welch algorithm</a> &nbsp; &nbsp;
                    
                <a href = "/">variational Bayes EM</a> &nbsp; &nbsp;
                    
                <a href = "/">Back propagation</a> &nbsp; &nbsp;
                    
                <a href = "/">reversible jump MCMC</a> &nbsp; &nbsp;
                    
                <a href = "/">convolutional neural nets</a> &nbsp; &nbsp;
                    

        #### Progress

        <a href = "/Tutorial/Machine Learning"> Statistics</a>

        